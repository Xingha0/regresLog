{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your code here# Univariate Analysis:\n",
                "# Histograms and boxplot for numeric variables.\n",
                "# Numeric variables: ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
                "\n",
                "import matplotlib.pyplot as plt \n",
                "import seaborn as sns\n",
                "\n",
                "fig, axis = plt.subplots(4, 5, figsize = (20, 10), gridspec_kw = {\"height_ratios\": [16, 4, 16, 4]})\n",
                "\n",
                "sns.histplot(ax = axis[0, 0], data = total_data, x = \"age\")\n",
                "sns.boxplot(ax = axis[1, 0], data = total_data, x = \"age\")\n",
                "\n",
                "sns.histplot(ax = axis[0, 1], data = total_data, x = \"duration\")\n",
                "sns.boxplot(ax = axis[1, 1], data = total_data, x = \"duration\")\n",
                "\n",
                "sns.histplot(ax = axis[0, 2], data = total_data, x = \"campaign\")\n",
                "sns.boxplot(ax = axis[1, 2], data = total_data, x = \"campaign\")\n",
                "\n",
                "sns.histplot(ax = axis[0, 3], data = total_data, x = \"pdays\")\n",
                "sns.boxplot(ax = axis[1, 3], data = total_data, x = \"pdays\")\n",
                "\n",
                "sns.histplot(ax = axis[0, 4], data = total_data, x = \"previous\")\n",
                "sns.boxplot(ax = axis[1, 4], data = total_data, x = \"previous\")\n",
                "\n",
                "sns.histplot(ax = axis[2, 0], data = total_data, x = \"emp.var.rate\")\n",
                "sns.boxplot(ax = axis[3, 0], data = total_data, x = \"emp.var.rate\")\n",
                "\n",
                "sns.histplot(ax = axis[2, 1], data = total_data, x = \"cons.price.idx\")\n",
                "sns.boxplot(ax = axis[3, 1], data = total_data, x = \"cons.price.idx\")\n",
                "\n",
                "sns.histplot(ax = axis[2, 2], data = total_data, x = \"cons.conf.idx\")\n",
                "sns.boxplot(ax = axis[3, 2], data = total_data, x = \"cons.conf.idx\")\n",
                "\n",
                "sns.histplot(ax = axis[2, 3], data = total_data, x = \"euribor3m\")\n",
                "sns.boxplot(ax = axis[3, 3], data = total_data, x = \"euribor3m\")\n",
                "\n",
                "sns.histplot(ax = axis[2, 4], data = total_data, x = \"nr.employed\")\n",
                "sns.boxplot(ax = axis[3, 4], data = total_data, x = \"nr.employed\")\n",
                "\n",
                "# Adjust layout\n",
                "plt.tight_layout()\n",
                "\n",
                "# Show the plot\n",
                "plt.show()\n",
                "# Groups inside Age category:\n",
                "age_types = total_data['nr.employed'].value_counts()\n",
                "percent_age = (age_types / len(total_data['nr.employed'])).round(3).sort_values(ascending = False) * 100\n",
                "print(percent_age.head(100))\n",
                "Conclusions for numeric analysis:\n",
                "- age: 31 - 50 years old\n",
                "- duration: 0 - 250 seconds\n",
                "- campaign: 1 - 5 contacts\n",
                "- pdays: 999 days\n",
                "- previous: 86.3% no, 11.1% once.\n",
                "- emp.var.rate: 39.4% for 1.4, 22.3% for -1.8 and 18.8% for 1.1.\n",
                "- cons.conf.idx: 93.994 18.8 / 93.918-16.2 / 92.893-14.1 / 93.444-12.6 / 94.465--10.6\n",
                "- euribor3m: 5\n",
                "- nr.employed: 5100 - 5200\n",
                "# Multivariate Analysis\n",
                "# Categorical-Categorical Analysis: we will compare some of the categorical variables with our target variable: y\n",
                "# Selected Categorical variables: ['job', 'marital', 'default', 'housing', 'loan', 'contact', 'month', 'y']\n",
                "\n",
                "agg_total_data = total_data.groupby(['y', 'housing', 'loan']).size().reset_index(name='count')\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "sns.barplot(x='y', y='count', hue='housing', data=agg_total_data, palette='Accent',ax=axes[0],)\n",
                "sns.barplot(x='y', y='count', hue='loan', data=agg_total_data, palette='Accent',ax=axes[1])\n",
                "- The marjority of clients that already have a housing loan or a personal loan reject the long-term deposit (y).\n",
                "# Multivariate Analysis\n",
                "# Numeric-Numeric Analysis\n",
                "# Selected Categorical variables: ['job', 'marital', 'default', 'housing', 'loan', 'contact', 'month', 'y']\n",
                "\n",
                "fig, axis = plt.subplots(figsize = (10, 6))\n",
                "\n",
                "sns.heatmap(total_data[numeric_variables].corr(), annot=True, fmt='.2f')\n",
                "\n",
                "# Adjust Layout\n",
                "plt.tight_layout()\n",
                "\n",
                "# Plot Layout\n",
                "plt.show()\n",
                "# We will copy the dataset to factorize the categorical variables in a new one:\n",
                "\n",
                "fact_data = total_data.copy()\n",
                "fact_data.head()\n",
                "fact_data[\"job\"] = pd.factorize(fact_data[\"job\"])[0]\n",
                "fact_data[\"marital\"] = pd.factorize(fact_data[\"marital\"])[0]\n",
                "fact_data[\"default\"] = pd.factorize(fact_data[\"default\"])[0]\n",
                "fact_data[\"housing\"] = pd.factorize(fact_data[\"housing\"])[0]\n",
                "fact_data[\"loan\"] = pd.factorize(fact_data[\"loan\"])[0]\n",
                "fact_data[\"contact\"] = pd.factorize(fact_data[\"contact\"])[0]\n",
                "fact_data[\"month\"] = pd.factorize(fact_data[\"month\"])[0]\n",
                "fact_data[\"poutcome\"] = pd.factorize(fact_data[\"poutcome\"])[0]\n",
                "fact_data[\"y\"] = pd.factorize(fact_data[\"y\"])[0]\n",
                "\n",
                "fig, axis = plt.subplots(figsize = (10, 6))\n",
                "\n",
                "sns.heatmap(fact_data[[\"job\", \"marital\", \"default\", \"housing\", \"loan\", \"contact\", \"month\", \"poutcome\" , \"y\"]].corr(), annot = True, fmt = \".2f\")\n",
                "\n",
                "plt.tight_layout()\n",
                "\n",
                "plt.show()\n",
                "Relevant relationship between:\n",
                "- contact-month: 0.43.\n",
                "- loan-housing: 0.29.\n",
                "- poutcome-Y: 0.27.\n",
                "# Complete correlation Heatmap:\n",
                "\n",
                "fig, axis = plt.subplots(figsize = (12, 12))\n",
                "\n",
                "sns.heatmap(fact_data[['job', 'marital', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome',  'age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'y']].corr(), annot = True, fmt = \".2f\")\n",
                "\n",
                "plt.tight_layout()\n",
                "\n",
                "plt.show()\n",
                "Important nonclusions:\n",
                "\n",
                "- Consumer Price Index, Euribor, Number of Employed People and Consumer Confidence all have tight correlations, as expected.\n",
                "- The duration of the calls have a nice correlation with our target y, the success of the customer taking long-term deposit.\n",
                "### Feature Engineering\n",
                "# Outlier Analysis:\n",
                "\n",
                "fact_data.describe()\n",
                "# Boxplots to Observe Outliers \n",
                "\n",
                "fig, axis = plt.subplots(6, 3, figsize=(15,15))\n",
                "\n",
                "sns.boxplot(ax=axis[0,0], data=fact_data, x = 'age')\n",
                "sns.boxplot(ax=axis[0,1], data=fact_data, x = 'duration')\n",
                "sns.boxplot(ax=axis[0,2], data=fact_data, x = 'campaign')\n",
                "sns.boxplot(ax=axis[1,0], data=fact_data, x = 'pdays')\n",
                "sns.boxplot(ax=axis[1,1], data=fact_data, x = 'previous')\n",
                "sns.boxplot(ax=axis[1,2], data=fact_data, x = 'emp.var.rate')\n",
                "sns.boxplot(ax=axis[2,0], data=fact_data, x = 'cons.price.idx')\n",
                "sns.boxplot(ax=axis[2,1], data=fact_data, x = 'cons.conf.idx')\n",
                "sns.boxplot(ax=axis[2,2], data=fact_data, x = 'euribor3m')\n",
                "sns.boxplot(ax=axis[3,0], data=fact_data, x = 'job')\n",
                "sns.boxplot(ax=axis[3,1], data=fact_data, x = 'marital')\n",
                "sns.boxplot(ax=axis[3,2], data=fact_data, x = 'default')\n",
                "sns.boxplot(ax=axis[4,0], data=fact_data, x = 'housing')\n",
                "sns.boxplot(ax=axis[4,1], data=fact_data, x = 'loan')\n",
                "sns.boxplot(ax=axis[4,2], data=fact_data, x = 'contact')\n",
                "sns.boxplot(ax=axis[5,0], data=fact_data, x = 'month')\n",
                "sns.boxplot(ax=axis[5,1], data=fact_data, x='poutcome')\n",
                "sns.boxplot(ax=axis[5,2], data=fact_data, x = 'y')\n",
                "\n",
                "plt.tight_layout()\n",
                "\n",
                "plt.show()\n",
                "We can see that some variables have outliers: age, duration, campaign, previous, consumer confidence, job, marital, loan, month, Y Target.\n",
                "\n",
                "Let's analyze if those Outliers should be kept, deleted or replaced.\n",
                "# Age Analysis\n",
                "\n",
                "age_stats = total_data['age'].describe()\n",
                "print(age_stats)\n",
                "# Age IQR\n",
                "\n",
                "age_iqr = age_stats['75%'] - age_stats['25%']\n",
                "upper_limit = age_stats['75%'] + 1.5 * age_iqr\n",
                "lower_limit = age_stats['25%'] - 1.5 * age_iqr\n",
                "\n",
                "print(f\"The upper and lower limits for finding outliers are {round(upper_limit, 2)} and {round(lower_limit, 2)}, with an interquartile range of {round(age_iqr, 2)}\")\n",
                "Despite showing that above 69.5 it's consider an Outlier, since Age for a Long Term Deposit is not an issue as a loan, we will keep Age with outliers.\n",
                "# Duration Analysis\n",
                "\n",
                "duration_stats = total_data['duration'].describe()\n",
                "print(duration_stats)\n",
                "# Duration IQR\n",
                "\n",
                "duration_iqr = duration_stats['75%'] - duration_stats['25%']\n",
                "upper_limit = duration_stats['75%'] + 1.5 * duration_iqr\n",
                "lower_limit = duration_stats['25%'] - 1.5 * duration_iqr\n",
                "\n",
                "print(f\"The upper and lower limits for finding outliers are {round(upper_limit, 2)} and {round(lower_limit, 2)}, with an interquartile range of {round(duration_iqr, 2)}\")\n",
                "4918 seconds (1 h 36 min) can perfectly happen in a call if the agent is succeeding and selling a product to costumer. Keeping the outliers here is important as well, as call duration can let us understand many patterns about success or failure.\n",
                "# Campaign Analysis\n",
                "\n",
                "campaign_stats = total_data['campaign'].describe()\n",
                "print(campaign_stats)\n",
                "# Campaign IQR\n",
                "\n",
                "campaign_iqr = campaign_stats['75%'] - campaign_stats['25%']\n",
                "upper_limit = campaign_stats['75%'] + 1.5 * campaign_iqr\n",
                "lower_limit = campaign_stats['25%'] - 1.5 * campaign_iqr\n",
                "\n",
                "print(f\"The upper and lower limits for finding outliers are {round(upper_limit, 2)} and {round(lower_limit, 2)}, with an interquartile range of {round(campaign_iqr, 2)}\")\n",
                "# Trimm the Outliers \n",
                "\n",
                "total_data = total_data[total_data[\"campaign\"] <= 15]\n",
                "Above 15 effective calls seems quite an odd number of contacts to a customer in a year.\n",
                "# Null Analysis:\n",
                "\n",
                "# Count the Nulls\n",
                "\n",
                "total_data.isnull().sum().sort_values(ascending=False)\n",
                "### Feature Scalling\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "\n",
                "num_variables = ['job', 'marital', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome' , 'age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'y']\n",
                "\n",
                "scaler = MinMaxScaler()\n",
                "scal_features = scaler.fit_transform(fact_data[num_variables])\n",
                "fact_data_scal = pd.DataFrame(scal_features, index = fact_data.index, columns = num_variables)\n",
                "fact_data_scal.head()\n",
                "### Feature Selection\n",
                "from sklearn.feature_selection import chi2, SelectKBest\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# We divide the dataset into training and test samples.\n",
                "X = fact_data_scal.drop('y', axis = 1)\n",
                "y = fact_data_scal['y']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
                "\n",
                "# KBest Selection for the best Features\n",
                "selection_model = SelectKBest(chi2, k = 5)\n",
                "selection_model.fit(X_train, y_train)\n",
                "ix = selection_model.get_support()\n",
                "X_train_sel = pd.DataFrame(selection_model.transform(X_train), columns = X_train.columns.values[ix])\n",
                "X_test_sel = pd.DataFrame(selection_model.transform(X_test), columns = X_test.columns.values[ix])\n",
                "\n",
                "X_train_sel.head()\n",
                "X_train_sel['y'] = list(y_train)\n",
                "X_test_sel['y'] = list(y_test)\n",
                "X_train_sel.to_csv('/workspaces/machine-learning-regresion-logistica-Juli-MM/data/processed/clean_train-bankmkt.csv', index=False)\n",
                "X_test_sel.to_csv('/workspaces/machine-learning-regresion-logistica-Juli-MM/data/processed/clean_test-bankmkt.csv', index=False)\n",
                "#### Step 3: Build a Logistic Regression Model\n",
                "# Import cleanned data:\n",
                "\n",
                "train_data = pd.read_csv('/workspaces/machine-learning-regresion-logistica-Juli-MM/data/processed/clean_train-bankmkt.csv')\n",
                "test_data = pd.read_csv('/workspaces/machine-learning-regresion-logistica-Juli-MM/data/processed/clean_test-bankmkt.csv')\n",
                "\n",
                "train_data.head()\n",
                "X_train = train_data.drop([\"y\"], axis = 1)\n",
                "y_train = train_data[\"y\"]\n",
                "X_test = test_data.drop([\"y\"], axis = 1)\n",
                "y_test = test_data[\"y\"]\n",
                "#### Initiate Model Training (Logistic Regression)\n",
                "\n",
                "We have selected Logistic Regression because we want to take a decision: Contract a long-term deposit or not.\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "\n",
                "model = LogisticRegression()\n",
                "model.fit(X_train, y_train)\n",
                "# Model prediction:\n",
                "\n",
                "y_pred = model.predict(X_test)\n",
                "y_pred\n",
                "# Accuracy Test\n",
                "\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "accuracy_score(y_test, y_pred)\n",
                "- Accuracy: 0.8936635105608157\n",
                "- In addition to the observed model score, it is common in classification problems to construct a confusion matrix, which is a table that is organized such that each row of the matrix represents instances of a predicted class, while each column represents instances of an actual class.\n",
                "# Confusion Matrix\n",
                "\n",
                "from sklearn.metrics import confusion_matrix\n",
                "\n",
                "bankmkt_cm = confusion_matrix(y_test, y_pred)\n",
                "\n",
                "# Let's draw this matrix to make it more visual\n",
                "\n",
                "cm_df = pd.DataFrame(bankmkt_cm)\n",
                "\n",
                "plt.figure(figsize = (3, 3))\n",
                "sns.heatmap(cm_df, annot=True, fmt=\"d\", cbar=False)\n",
                "\n",
                "plt.tight_layout()\n",
                "\n",
                "plt.show()\n",
                "\n",
                "Conclusions:\n",
                "\n",
                "- True negative (TN): Corresponds to the number 7224 and are the cases where the model predicted negative (reject long-term deposit) and the actual class is also negative.\n",
                "- False negative (FN): Corresponds to the number 797 and are the cases where the model predicted negative, but the actual class is positive.\n",
                "- True positive (TP): corresponds to the number 138 and are the cases where the model predicted positive (contract long-term deposit) and the actual class is also positive.\n",
                "- False positive (FP): Corresponds to the number 79 and are the cases in which the model predicted positive, but the actual class is negative.\n",
                "#### Step 4: Optimize the previous model\n",
                "#### Hyperparameter Optimization\n",
                "\n",
                "- Actually: 0.8936635105608157\n",
                "from sklearn.model_selection import GridSearchCV\n",
                "\n",
                "# We define the parameters that we want to adjust by hand:\n",
                "\n",
                "hyperparams = {\n",
                "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
                "    \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None],\n",
                "    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
                "    }\n",
                "\n",
                "# We initialize the grid\n",
                "\n",
                "grid = GridSearchCV(model, hyperparams, scoring = \"accuracy\", cv = 5)\n",
                "grid\n",
                "# Launch Results\n",
                "\n",
                "grid.fit(X_train, y_train)\n",
                "\n",
                "print(f\"Best hyperparameters: {grid.best_params_}\")\n",
                "Result: Best hyperparameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
                "# Model Run with new Parameters\n",
                "\n",
                "model_grid = LogisticRegression(penalty = \"l2\", C = 0.1, solver = \"liblinear\")\n",
                "model_grid.fit(X_train, y_train)\n",
                "y_pred = model_grid.predict(X_test)\n",
                "\n",
                "grid_accuracy = accuracy_score(y_test, y_pred)\n",
                "grid_accuracy\n",
                "- With new parameters the accuracy increases to 0.8954843408594318. \n",
                "- The increase was of 0.2% which is not significant. Let's try with other Optimization Method: Random Search Optimization.\n",
                "#### Random Search Optimization\n",
                "import numpy as np\n",
                "from sklearn.model_selection import RandomizedSearchCV\n",
                "\n",
                "# We define the parameters we want to adjust\n",
                "\n",
                "hyperparams = {\n",
                "    \"C\": np.logspace(-4, 4, 20),\n",
                "    \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None],\n",
                "    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
                "}\n",
                "\n",
                "# We initialize the random search\n",
                "random_search = RandomizedSearchCV(model, hyperparams, n_iter = 100, scoring = \"accuracy\", cv = 5, random_state = 42)\n",
                "random_search\n",
                "random_search.fit(X_train, y_train)\n",
                "\n",
                "print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
                "Result: Best hyperparameters: {'solver': 'sag', 'penalty': 'l2', 'C': 0.08858667904100823}\n",
                "# # Retrain the Model with new Parameters\n",
                "\n",
                "model_grid = LogisticRegression(penalty = \"l2\", C = 0.08858667904100823, solver = \"sag\")\n",
                "model_grid.fit(X_train, y_train)\n",
                "y_pred = model_grid.predict(X_test)\n",
                "\n",
                "grid_accuracy = accuracy_score(y_test, y_pred)\n",
                "grid_accuracy"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
